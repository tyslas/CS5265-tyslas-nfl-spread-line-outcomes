{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/tyslas/CS5265-tyslas-nfl-spread-line-outcomes/blob/main/NFLSpreadAndLineOutcomes.ipynb",
      "authorship_tag": "ABX9TyN0C6gkFUQ5qh+WD+U4KUgk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyslas/CS5265-tyslas-nfl-spread-line-outcomes/blob/main/NFLSpreadAndLineOutcomes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Project to predict future NFL Spread & Line outcomes\n",
        "\n",
        "## Author: Tito Yslas\n",
        "\n",
        "### Background\n",
        "I enjoy watching the NFL and playing fantasy football. I also like to place bets on games using apps like FanDuel. The purpose of this project is to increase my understanding of the NFL betting market and possibly create a machine learning model to give myself an edge next season.\n",
        "\n",
        "### Project Description\n",
        "I found a dataset from Kaggle titled [NFL scores and betting data](https://www.kaggle.com/datasets/tobycrabtree/nfl-scores-and-betting-data?resource=download). This dataset has over 13,000 samples and 17 features. The goal is to use this dataset to train a model that will predict the winner of a given game.\n",
        "\n",
        "### Performance Metric\n",
        "For my performance metric, I will aim for the model to have at least 70% accuracy."
      ],
      "metadata": {
        "id": "AB1jvMR96flY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "9BTvFVEI9cf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "hqcOze6S9aFh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data\n",
        "\n",
        "### Data Dictionary\n",
        "- schedule_date: Date that the game took place. This column is a date in the format MM/DD/YYYY\n",
        "- schedule_season: Year of the season began. NFL seasons start in the fall and end before the spring of the following year. So the 2023 season will refer to the years 2023-2024. This column is a number in the format YYYY\n",
        "- schedule_week: Week of the NFL season. This column is either a number during regular season weeks or a string in playoff weeks. For the purposes of this project the playoff weeks will be converted to numbers and the schedule_playoff column will be used to determine whether the week is a playoff game or not\n",
        "- schedule_playoff: This column is a boolean. FALSE is regular season and TRUE is playoffs\n",
        "- team_home: Name of the home team. This column is a string\n",
        "- score_home: Points scored by the home team. This column is a number\n",
        "- score_away: Points scored by the away team. This column is a number\n",
        "- winner: This column will be a feature derived from score_home and score_away columns to that will use one hot encoding - if team_home scores more points this will be a 1 - if team_home scores fewer points it will be a 0\n",
        "- team_away: Name of the away team. This column is a string\n",
        "- team_favorite_id: Acronym of the team that was determined most likely to win by the betting market. It is either two or three letters. For the purposes of this project this column will be changed to be either the team_home or team_away name\n",
        "- team_home_favorite: this will represent the encoded team_favorite_id - if team_home is favored this column will be marked as a 1 - if it's a zero then we know that team_away is favored\n",
        "- spread_favorite: The number of points that the favored team needs to win by for a bet placed on the spread of the favorite to win. This column will either be a negative number or zero\n",
        "- over_under_line: The number of points that both teams combined need to score for a bet placed on the 'line' to win. This column is a positive number\n",
        "- stadium: Name of the venue that the game is played\n",
        "- stadium_neutral: This column is a boolean. FALSE is not a neutral venue and TRUE is a neutral venue - for the purposes of this project this column will be one hot encoded with a neutral venue being marked as a 1 and non-neutral marked as a 0\n",
        "- weather_temperature: The temperature in Fahrenheit at the venue where the game is played. This column is a number\n",
        "- weather_wind_mph: The speed of wind in miles per hour. This column is a number\n",
        "- weather_humidity: The measurement of water vapor in the air during the game measured as a percentage. This column is a number\n",
        "- weather_detail: Other information about the weather conditions - if the venue is indoor or the venue has a retractable roof. This column is a string\n"
      ],
      "metadata": {
        "id": "pW84W_CR9gbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n",
        "### Questions to answer with EDA:\n",
        "1. Which columns, if any, should I modify the data type to better train my model?\n",
        "1. Which columns, if any, should I remove from the training and test data so that the model can be effectively trained?\n",
        "1. Which columns, if any, should I remove or insert derived data for in the case that there is a lot of missing data?\n",
        "1. What features could it make sense to introduce to improve the training and performance of my model?"
      ],
      "metadata": {
        "id": "qS7aUTCi-IcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# change directory to relevant files\n",
        "%cd /content/drive/MyDrive/vandy/nfl\n",
        "# print all file names in directory\n",
        "for file in os.listdir():\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "Dws_uGxH63s7",
        "outputId": "0cc14175-03de-4a82-b823-52d7cae9a945"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/vandy/nfl\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4d403859e63c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/vandy/nfl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print all file names in directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = pd.read_csv('spreadspoke_scores.csv')"
      ],
      "metadata": {
        "id": "BidRFzFS-MbB",
        "outputId": "8e70bef7-686b-40fe-e438-ad7c1b9de29a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8409f16bd073>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spreadspoke_scores.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores.info()\n",
        "# scores.describe()"
      ],
      "metadata": {
        "id": "UZTfe47yGnOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ede7765-f396-460c-e7f7-cd5b981415f6"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13516 entries, 0 to 13515\n",
            "Data columns (total 17 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   schedule_date        13516 non-null  object \n",
            " 1   schedule_season      13516 non-null  int64  \n",
            " 2   schedule_week        13516 non-null  object \n",
            " 3   schedule_playoff     13516 non-null  bool   \n",
            " 4   team_home            13516 non-null  object \n",
            " 5   score_home           13516 non-null  int64  \n",
            " 6   score_away           13516 non-null  int64  \n",
            " 7   team_away            13516 non-null  object \n",
            " 8   team_favorite_id     11037 non-null  object \n",
            " 9   spread_favorite      11037 non-null  float64\n",
            " 10  over_under_line      11027 non-null  object \n",
            " 11  stadium              13516 non-null  object \n",
            " 12  stadium_neutral      13516 non-null  bool   \n",
            " 13  weather_temperature  12309 non-null  float64\n",
            " 14  weather_wind_mph     12293 non-null  float64\n",
            " 15  weather_humidity     8468 non-null   float64\n",
            " 16  weather_detail       2919 non-null   object \n",
            "dtypes: bool(2), float64(4), int64(3), object(8)\n",
            "memory usage: 1.6+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer to Question 1\n",
        "- I think that it makes sense to modify both team_home and team_away to have the same IDs as team_favorite_id to make it easier for the model to indentify when team_home is the same or different as team_favorite_id\n",
        "- Currently Pandas is indentifying schedule_date as an object, it could make sense to see if there's a way for Pandas to indentify this as a date\n",
        "- Currently Pandas is indentifying schedule_week as an object. This is because some of the data in this column is in string format. It could make sense to modify the data of this column that is in a string to only be in int64 format and use the schedule_playoff column to be the soe determination of whether or not the schedule_week is a playoff game\n",
        "- Currently Pandas is indentifying the over_under_line column as an object data type despite the fact that it should be a float. I will explore how to ensure that this column's data type is correctly identified\n",
        "- The stadium_neutral column is currently a boolean type, I think I will convert this to use one hot encoding instead"
      ],
      "metadata": {
        "id": "0LOL15VkNu2F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer to Question 2\n",
        "- Based on my initial examination, I'm not sure if it makes sense to remove any of my columns from the data set on which I will train my model"
      ],
      "metadata": {
        "id": "5XaePv3MQqLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores.isna().sum() # number of missing values for each column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wiWTfZTCuEr",
        "outputId": "cb41fcb1-0d09-4367-a8fb-8dfd6917dacf"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "schedule_date              0\n",
              "schedule_season            0\n",
              "schedule_week              0\n",
              "schedule_playoff           0\n",
              "team_home                  0\n",
              "score_home                 0\n",
              "score_away                 0\n",
              "team_away                  0\n",
              "team_favorite_id        2479\n",
              "spread_favorite         2479\n",
              "over_under_line         2489\n",
              "stadium                    0\n",
              "stadium_neutral            0\n",
              "weather_temperature     1207\n",
              "weather_wind_mph        1223\n",
              "weather_humidity        5048\n",
              "weather_detail         10597\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer to Question 3\n",
        "- the columns with missing data include team_favorite_id, spread_favorite, over_under_line, weather_temperature, weather_wind_mph, weather_humidity, and weather_detail. these columns have many missing values because this data was not collected in earlier seasons. for example, there is minimal team_favorite_id information collected from the 1978 schedule_season and previous to that likely because of the lack of public betting information before that time\n",
        "- for the missing data I don't think that it makes sense to remove these columns, however it might make sense to only train and test on the observations from the 1979 schedule_season and beyond"
      ],
      "metadata": {
        "id": "6AD4kleLK_5Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Answer to Question 4\n",
        "- I think it makes sense to introduce/derive three different target columns for understanding the performance of the model\n",
        "- The three target columns I am thinking about introducing are derived from score_home, score_away, and over_under_line\n",
        "- These targets would be one hot encoded as team_home_win, team_home_cover_spread, and cover_line\n",
        "- team_home_win would be a 1 if team_home wins or a 0 if they lose\n",
        "- team_home_cover_spread would be a 1 if they cover the spread_favorite and a 0 if they don't\n",
        "- cover_line would be a 1 if score_home + score_way is greater than the over_under_line and a 0 if it's less than"
      ],
      "metadata": {
        "id": "SF4mwL9RSDqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering\n",
        "1. convert `schedule_date` column to actually be read in as a date/time object instead of generic object\n",
        "1. convert `schedule_week` to only be numbers - this could be more challenging than I initially thought because there will not be direct mappings for the outliers of `Division`, `Wild Card`, `Conference`, and `Superbowl` because the NFL has expanded the numbers of games played during the regular season over the years and added in the `Wildcard` games\n",
        "1. convert the `schedule_playoff` column from true/false to 1/0\n",
        "1. add a target/feature of `winning_team` to be derived from `score_home` and `score_away` to make it easier to determine how the model performs\n",
        "1. convert all `team_home` and `team_away` entries to the acronym identifiers\n",
        "1. drop rows 0 - 2499 because they don't have data for `team_favorite_id`, `spread_favorite` and `over_under_line`\n",
        "1. create new target column of `favorite_won` with 1 for true and 0 for false\n",
        "1. create new target column of `spread_favorite_covered` with 1 for true and 0 for false\n",
        "1. create new target column of `over_under_covered`\n",
        "1. convert the `weather_detail` column to a categorical variable that is one-hot encoded"
      ],
      "metadata": {
        "id": "vC55HpdhA6pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert schedule_date to proper date type\n",
        "scores['schedule_date'] = pd.to_datetime(scores['schedule_date'])\n",
        "schedule_date_data_type = scores['schedule_date'].dtype\n",
        "print('data type of schedule_date: ', schedule_date_data_type)"
      ],
      "metadata": {
        "id": "ZjkoX1TOCZO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert schedule_week to only be numbers\n",
        "scores['schedule_week'].value_counts()\n",
        "# this may require a fair amount of time spent manually mapping week numbers"
      ],
      "metadata": {
        "id": "nUDw45zjDgEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the schedule_playoff column from true/false into 1/0\n",
        "scores['schedule_playoff'] = scores['schedule_playoff'].astype(int)\n",
        "display(scores)"
      ],
      "metadata": {
        "id": "DMXMYNjfJ7fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert all team_home and team_away entries to the acronym identifiers\n",
        "\n",
        "# map of team names and their corresponding IDs\n",
        "team_ids = {\n",
        "    'San Francisco 49ers': 'SF',\n",
        "    'Dallas Cowboys': 'DAL',\n",
        "    'Pittsburgh Steelers': 'PIT',\n",
        "    'Green Bay Packers': 'GB',\n",
        "    'Philadelphia Eagles': 'PHI',\n",
        "    'Minnesota Vikings': 'MIN',\n",
        "    'Denver Broncos': 'DEN',\n",
        "    'Miami Dolphins': 'MIA',\n",
        "    'Kansas City Chiefs': 'KC',\n",
        "    'Buffalo Bills': 'BUF',\n",
        "    'Chicago Bears': 'CHI',\n",
        "    'New York Giants': 'NYG',\n",
        "    'Atlanta Falcons': 'ATL',\n",
        "    'New Orleans Saints': 'NO',\n",
        "    'New York Jets': 'NYJ',\n",
        "    'Detroit Lions': 'DET',\n",
        "    'Cincinnati Bengals': 'CIN',\n",
        "    'New England Patriots': 'NE',\n",
        "    'Washington Redskins': 'WAS',\n",
        "    'Cleveland Browns': 'CLE',\n",
        "    # should be SD but all the data uses LAC\n",
        "    'San Diego Chargers': 'LAC',\n",
        "    'Seattle Seahawks': 'SEA',\n",
        "    'Tampa Bay Buccaneers': 'TB',\n",
        "    # should be OAK but all the data uses LVR\n",
        "    'Oakland Raiders': 'LVR',\n",
        "    'Indianapolis Colts': 'IND',\n",
        "    'Los Angeles Rams': 'LAR',\n",
        "    'Arizona Cardinals': 'ARI',\n",
        "    # should be HOU but all the data uses TEN\n",
        "    'Houston Oilers': 'TEN',\n",
        "    'Carolina Panthers': 'CAR',\n",
        "    'Jacksonville Jaguars': 'JAX',\n",
        "    'Baltimore Ravens': 'BAL',\n",
        "    'Tennessee Titans': 'TEN',\n",
        "    # should be STL but all the data uses LAR\n",
        "    'St. Louis Rams': 'LAR',\n",
        "    'Houston Texans': 'HOU',\n",
        "    # should be STL but all the data uses ARI\n",
        "    'St. Louis Cardinals': 'ARI',\n",
        "    'Baltimore Colts': 'BAL',\n",
        "    # should be LAR but all the data uses LVR\n",
        "    'Los Angeles Raiders': 'LVR',\n",
        "    'Los Angeles Chargers': 'LAC',\n",
        "    # should be PHX but all the data uses ARI\n",
        "    'Phoenix Cardinals': 'ARI',\n",
        "    # 'Boston Patriots': '', the franchise changed the name of their team to the New England Patriots in 1971\n",
        "    # the data does not have any team_favorite_id listed before the 12/24/78 in the 1978 season (row 2494)\n",
        "    'Las Vegas Raiders': 'LVR',\n",
        "    'Washington Football Team': 'WAS',\n",
        "    'Tennessee Oilers': 'TEN',\n",
        "    'Washington Commanders': 'WAS',\n",
        "}\n",
        "\n",
        "scores['team_home'] = scores['team_home'].replace(team_ids)\n",
        "scores['team_away'] = scores['team_away'].replace(team_ids)\n",
        "\n",
        "scores.loc[2492:2502]"
      ],
      "metadata": {
        "id": "FeAiLun1oySV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a target/feature of 'winning_team'\n",
        "# Derive a new column based on the comparison of two existing columns\n",
        "def determine_winner(row):\n",
        "  if row['score_home'] > row['score_away']:\n",
        "    val = row['team_home']\n",
        "  elif row['score_home'] == row['score_away']:\n",
        "    val = 'tie'\n",
        "  else:\n",
        "    val = row['team_away']\n",
        "  return val\n",
        "\n",
        "scores['winning_team'] = scores.apply(determine_winner, axis=1)\n",
        "print(scores['winning_team'].tail(20))\n",
        "print('number of ties:', scores['winning_team'].value_counts()['tie'])"
      ],
      "metadata": {
        "id": "ece_4C4XNUEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop rows 0 - 2499 because they don't have data for team_favorite_id, spread_favorite and over_under_line\n",
        "start_index = 0\n",
        "end_index = 2500\n",
        "\n",
        "scores_dropped = scores.drop(scores.index[start_index:end_index])\n",
        "scores_dropped.head(20)"
      ],
      "metadata": {
        "id": "586CY36v2C_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new target column of favorite_won with 1 for true and 0 for false\n",
        "# the favorite_won column is returning an float instead of an int -- need to fix\n",
        "\n",
        "def determine_favorite_won(row):\n",
        "  result = 1\n",
        "  if row['winning_team'] != row['team_favorite_id']:\n",
        "    result = 0\n",
        "  return int(result)\n",
        "\n",
        "scores_dropped.loc[2500:, 'favorite_won'] = scores_dropped.loc[2500:].apply(determine_favorite_won, axis = 1)\n",
        "scores_dropped.loc[2500:, 'favorite_won'] = scores_dropped.loc[2500:, 'favorite_won'].astype(int)\n",
        "scores_dropped.head()"
      ],
      "metadata": {
        "id": "NAtlWMo-LX8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new target column of spread_favorite_covered with 1 for true and 0 for false\n",
        "# the favorite_won column is returning an float instead of an int -- need to fix\n",
        "\n",
        "def determine_favorite_covered_spread(row):\n",
        "  return 1 if row['score_home'] - row['score_away'] > abs(row['spread_favorite']) else 0\n",
        "\n",
        "scores_dropped.loc[2492:, 'spread_favorite_covered'] = scores_dropped.loc[2492:].apply(determine_favorite_covered_spread, axis = 1)\n",
        "display(scores_dropped.head(20))\n",
        "print('counts:\\n',scores_dropped['spread_favorite_covered'].value_counts())"
      ],
      "metadata": {
        "id": "3-i2gIEzlnQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create new target column of over_under_covered\n",
        "\n",
        "# need to cast over_under_line column to a float -- pandas recognizes it as a string\n",
        "scores_dropped.loc[2500:, 'over_under_line'] = pd.to_numeric(scores_dropped.loc[2500:, 'over_under_line'], errors='coerce')\n",
        "# scores_dropped.loc[2500:, 'over_under_line'].astype(float)\n",
        "print(scores_dropped['over_under_line'].dtypes)\n",
        "def determine_over_under_covered(row):\n",
        "  return 1 if int(row['score_home'] + row['score_away']) > row['over_under_line'] else 0\n",
        "\n",
        "scores_dropped.loc[2500:, 'over_under_covered'] = scores_dropped.loc[2500:].apply(determine_over_under_covered, axis = 1)\n",
        "display(scores_dropped[['score_home', 'score_away', 'over_under_line', 'over_under_covered']].head(20))\n",
        "print('counts:\\n',scores_dropped['over_under_covered'].value_counts())"
      ],
      "metadata": {
        "id": "z6SUSps30HCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert the weather_detail column to categorical variable that is one-hot encoded\n",
        "scores_dropped.loc[2500:, 'weather_detail'].value_counts()"
      ],
      "metadata": {
        "id": "zZr-5aO-oShN",
        "outputId": "deebffba-13b2-4747-8377-2d19605d9e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9ebbbadfbb70>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert the weather_detail column to categorical variable that is one-hot encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores_dropped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weather_detail'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scores_dropped' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split"
      ],
      "metadata": {
        "id": "BuNTBorhmpyA"
      }
    }
  ]
}